{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274b5f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yjagilanka/Desktop/sem2/DIC/Document_Retrieval_NLP'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e1fbd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yjagilanka/Desktop/sem2/DIC/Document_Retrieval_NLP/data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359956c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yjagilanka/Desktop/sem2/DIC/Document_Retrieval_NLP/data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b04776d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mOutputFiles_ComputerScience\u001b[m\u001b[m/ \u001b[34mOutputFiles_ComputerVision\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccb2fb0-9bba-44ea-adb7-7f068c3617d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yjagilanka/Desktop/sem2/DIC/Document_Retrieval_NLP/data/OutputFiles_ComputerVision\n"
     ]
    }
   ],
   "source": [
    "cd OutputFiles_ComputerVision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc816222-f0c9-4bc5-b389-79e33417a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2b4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('trans_sub_df.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddfe480b-5714-4c56-b4ce-f30e12935432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>categories</th>\n",
       "      <th>authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>cat_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1207.2602</td>\n",
       "      <td>A Novel Approach Coloured Object Tracker with ...</td>\n",
       "      <td>The traditional color-based mean-shift track...</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>Seyed Amir Mohammadi and Mohammad Reza Mahzoun</td>\n",
       "      <td>2021</td>\n",
       "      <td>Computer Vision and Pattern Recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1606.09549</td>\n",
       "      <td>Fully-Convolutional Siamese Networks for Objec...</td>\n",
       "      <td>The problem of arbitrary object tracking has...</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>Luca Bertinetto, Jack Valmadre, Jo\\~ao F. Henr...</td>\n",
       "      <td>2021</td>\n",
       "      <td>Computer Vision and Pattern Recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1607.01205</td>\n",
       "      <td>Learning the semantic structure of objects fro...</td>\n",
       "      <td>While recent research in image understanding...</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>David Novotny, Diane Larlus, Andrea Vedaldi</td>\n",
       "      <td>2021</td>\n",
       "      <td>Computer Vision and Pattern Recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1609.04382</td>\n",
       "      <td>Warped Convolutions: Efficient Invariance to S...</td>\n",
       "      <td>Convolutional Neural Networks (CNNs) are ext...</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>Jo\\~ao F. Henriques, Andrea Vedaldi</td>\n",
       "      <td>2021</td>\n",
       "      <td>Computer Vision and Pattern Recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1611.02302</td>\n",
       "      <td>Quantum spectral analysis: frequency in time, ...</td>\n",
       "      <td>A quantum time-dependent spectrum analysis, ...</td>\n",
       "      <td>cs.CV</td>\n",
       "      <td>Mario Mastriani</td>\n",
       "      <td>2021</td>\n",
       "      <td>Computer Vision and Pattern Recognition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              title  \\\n",
       "0   1207.2602  A Novel Approach Coloured Object Tracker with ...   \n",
       "1  1606.09549  Fully-Convolutional Siamese Networks for Objec...   \n",
       "2  1607.01205  Learning the semantic structure of objects fro...   \n",
       "3  1609.04382  Warped Convolutions: Efficient Invariance to S...   \n",
       "4  1611.02302  Quantum spectral analysis: frequency in time, ...   \n",
       "\n",
       "                                            abstract categories  \\\n",
       "0    The traditional color-based mean-shift track...      cs.CV   \n",
       "1    The problem of arbitrary object tracking has...      cs.CV   \n",
       "2    While recent research in image understanding...      cs.CV   \n",
       "3    Convolutional Neural Networks (CNNs) are ext...      cs.CV   \n",
       "4    A quantum time-dependent spectrum analysis, ...      cs.CV   \n",
       "\n",
       "                                             authors  Year  \\\n",
       "0     Seyed Amir Mohammadi and Mohammad Reza Mahzoun  2021   \n",
       "1  Luca Bertinetto, Jack Valmadre, Jo\\~ao F. Henr...  2021   \n",
       "2        David Novotny, Diane Larlus, Andrea Vedaldi  2021   \n",
       "3                Jo\\~ao F. Henriques, Andrea Vedaldi  2021   \n",
       "4                                    Mario Mastriani  2021   \n",
       "\n",
       "                                  cat_desc  \n",
       "0  Computer Vision and Pattern Recognition  \n",
       "1  Computer Vision and Pattern Recognition  \n",
       "2  Computer Vision and Pattern Recognition  \n",
       "3  Computer Vision and Pattern Recognition  \n",
       "4  Computer Vision and Pattern Recognition  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e177ed61-6c77-4b2f-82e1-a93f6ae67020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtopics_LDA.parquet\u001b[m\u001b[m/                \u001b[34mtrans_sub_df_tfidf.parquet\u001b[m\u001b[m/\n",
      "\u001b[34mtrans_sub_df.parquet\u001b[m\u001b[m/              \u001b[34mtransformed_LDA_TopicDist.parquet\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0ce5a63-6472-4efd-93ec-b1e196c9c7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics = pd.read_parquet('topics_LDA.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ab91af-6ef1-4213-854b-b24dd79bf027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "      <th>words_in_topic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[147, 548, 582, 545, 111, 440, 216, 947, 1304,...</td>\n",
       "      <td>[0.03083287756068621, 0.029005778632855295, 0....</td>\n",
       "      <td>[graph, teacher, student, distillation, knowle...</td>\n",
       "      <td>0704.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[62, 58, 133, 14, 630, 129, 675, 843, 746, 345...</td>\n",
       "      <td>[0.01291275326940837, 0.01253613854152138, 0.0...</td>\n",
       "      <td>[loss, sample, classes, training, negative, di...</td>\n",
       "      <td>0704.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[206, 1016, 849, 1291, 1129, 1928, 121, 1596, ...</td>\n",
       "      <td>[0.059861027030421406, 0.016611345477843, 0.01...</td>\n",
       "      <td>[search, parse, path, nas, dnns, table, archit...</td>\n",
       "      <td>0704.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[92, 134, 4, 3, 243, 100, 43, 19, 271, 47, 465...</td>\n",
       "      <td>[0.01033774445589718, 0.006992914610126593, 0....</td>\n",
       "      <td>[transformer, layer, feature, network, cnn, co...</td>\n",
       "      <td>0704.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[574, 61, 706, 1107, 1481, 1105, 750, 4, 47, 5...</td>\n",
       "      <td>[0.018503305682521485, 0.017387506419040764, 0...</td>\n",
       "      <td>[boundary, attention, saliency, multilabel, fi...</td>\n",
       "      <td>0704.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                                        termIndices  \\\n",
       "0      0  [147, 548, 582, 545, 111, 440, 216, 947, 1304,...   \n",
       "1      1  [62, 58, 133, 14, 630, 129, 675, 843, 746, 345...   \n",
       "2      2  [206, 1016, 849, 1291, 1129, 1928, 121, 1596, ...   \n",
       "3      3  [92, 134, 4, 3, 243, 100, 43, 19, 271, 47, 465...   \n",
       "4      4  [574, 61, 706, 1107, 1481, 1105, 750, 4, 47, 5...   \n",
       "\n",
       "                                         termWeights  \\\n",
       "0  [0.03083287756068621, 0.029005778632855295, 0....   \n",
       "1  [0.01291275326940837, 0.01253613854152138, 0.0...   \n",
       "2  [0.059861027030421406, 0.016611345477843, 0.01...   \n",
       "3  [0.01033774445589718, 0.006992914610126593, 0....   \n",
       "4  [0.018503305682521485, 0.017387506419040764, 0...   \n",
       "\n",
       "                                      words_in_topic         id  \n",
       "0  [graph, teacher, student, distillation, knowle...  0704.0001  \n",
       "1  [loss, sample, classes, training, negative, di...  0704.0002  \n",
       "2  [search, parse, path, nas, dnns, table, archit...  0704.0003  \n",
       "3  [transformer, layer, feature, network, cnn, co...  0704.0004  \n",
       "4  [boundary, attention, saliency, multilabel, fi...  0704.0005  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d782ac94-0a96-435f-8ea0-72b4544956a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.416057\n",
       "1     0.237435\n",
       "2     0.356116\n",
       "3     0.208332\n",
       "4     0.291209\n",
       "5     0.292808\n",
       "6     0.255771\n",
       "7     0.338634\n",
       "8     0.214747\n",
       "9     0.278873\n",
       "10    0.322176\n",
       "11    0.304395\n",
       "12    0.253899\n",
       "13    0.334769\n",
       "14    0.260981\n",
       "15    0.234877\n",
       "16    0.268736\n",
       "17    0.246398\n",
       "18    0.271238\n",
       "19    0.167004\n",
       "Name: termWeights, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics.termWeights.apply(lambda x : sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2150ebbb-cfa5-4d2e-ae87-56a217996b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topics1 = pd.read_parquet('transformed_LDA_TopicDist.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbafbeb2-0f5d-4d95-ae5c-9d24c3890470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finshed_lemma</th>\n",
       "      <th>id</th>\n",
       "      <th>features_cv.type</th>\n",
       "      <th>features_cv.size</th>\n",
       "      <th>features_cv.indices</th>\n",
       "      <th>features_cv.values</th>\n",
       "      <th>features_idf.type</th>\n",
       "      <th>features_idf.size</th>\n",
       "      <th>features_idf.indices</th>\n",
       "      <th>features_idf.values</th>\n",
       "      <th>topicDistribution.type</th>\n",
       "      <th>topicDistribution.size</th>\n",
       "      <th>topicDistribution.indices</th>\n",
       "      <th>topicDistribution.values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[traditional, colorbased, meanshift, track, al...</td>\n",
       "      <td>0704.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[1, 7, 11, 13, 16, 21, 27, 34, 36, 37, 65, 67,...</td>\n",
       "      <td>[2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[1, 7, 11, 13, 16, 21, 27, 34, 36, 37, 65, 67,...</td>\n",
       "      <td>[1.264359629051574, 2.672235245786502, 0.78028...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0002747257643554155, 0.000370430728967976, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[problem, arbitrary, object, track, traditiona...</td>\n",
       "      <td>0704.0002</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 9, 12, 14, 15, 16, 17, 2...</td>\n",
       "      <td>[2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[1, 2, 3, 5, 6, 7, 8, 9, 12, 14, 15, 16, 17, 2...</td>\n",
       "      <td>[1.264359629051574, 1.3312618459798278, 2.1505...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.00017208621082816756, 0.06247647418345954, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[recent, research, image, understand, often, f...</td>\n",
       "      <td>0704.0003</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[0, 2, 7, 11, 13, 16, 37, 40, 42, 57, 66, 69, ...</td>\n",
       "      <td>[3.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[0, 2, 7, 11, 13, 16, 37, 40, 42, 57, 66, 69, ...</td>\n",
       "      <td>[1.8672845100989752, 1.9968927689697415, 8.016...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.02121493851041644, 0.0002204081812410088, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[convolutional, neural, network, cnns, extreme...</td>\n",
       "      <td>0704.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[0, 2, 3, 5, 11, 13, 18, 29, 34, 41, 45, 54, 5...</td>\n",
       "      <td>[2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[0, 2, 3, 5, 11, 13, 18, 29, 34, 41, 45, 54, 5...</td>\n",
       "      <td>[1.2448563400659836, 0.6656309229899139, 0.716...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.000144603163285717, 0.00019497790948735233,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[quantum, timedependent, spectrum, analysis, s...</td>\n",
       "      <td>0704.0005</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[0, 12, 27, 31, 40, 56, 73, 74, 80, 97, 101, 1...</td>\n",
       "      <td>[3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4444</td>\n",
       "      <td>[0, 12, 27, 31, 40, 56, 73, 74, 80, 97, 101, 1...</td>\n",
       "      <td>[1.8672845100989752, 2.9135879822916877, 3.598...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[7.505867153142022e-05, 0.0001012065188320117,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       finshed_lemma         id  \\\n",
       "0  [traditional, colorbased, meanshift, track, al...  0704.0001   \n",
       "1  [problem, arbitrary, object, track, traditiona...  0704.0002   \n",
       "2  [recent, research, image, understand, often, f...  0704.0003   \n",
       "3  [convolutional, neural, network, cnns, extreme...  0704.0004   \n",
       "4  [quantum, timedependent, spectrum, analysis, s...  0704.0005   \n",
       "\n",
       "   features_cv.type  features_cv.size  \\\n",
       "0                 0              4444   \n",
       "1                 0              4444   \n",
       "2                 0              4444   \n",
       "3                 0              4444   \n",
       "4                 0              4444   \n",
       "\n",
       "                                 features_cv.indices  \\\n",
       "0  [1, 7, 11, 13, 16, 21, 27, 34, 36, 37, 65, 67,...   \n",
       "1  [1, 2, 3, 5, 6, 7, 8, 9, 12, 14, 15, 16, 17, 2...   \n",
       "2  [0, 2, 7, 11, 13, 16, 37, 40, 42, 57, 66, 69, ...   \n",
       "3  [0, 2, 3, 5, 11, 13, 18, 29, 34, 41, 45, 54, 5...   \n",
       "4  [0, 12, 27, 31, 40, 56, 73, 74, 80, 97, 101, 1...   \n",
       "\n",
       "                                  features_cv.values  features_idf.type  \\\n",
       "0  [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                  0   \n",
       "1  [2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, ...                  0   \n",
       "2  [3.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, ...                  0   \n",
       "3  [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, ...                  0   \n",
       "4  [3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, ...                  0   \n",
       "\n",
       "   features_idf.size                               features_idf.indices  \\\n",
       "0               4444  [1, 7, 11, 13, 16, 21, 27, 34, 36, 37, 65, 67,...   \n",
       "1               4444  [1, 2, 3, 5, 6, 7, 8, 9, 12, 14, 15, 16, 17, 2...   \n",
       "2               4444  [0, 2, 7, 11, 13, 16, 37, 40, 42, 57, 66, 69, ...   \n",
       "3               4444  [0, 2, 3, 5, 11, 13, 18, 29, 34, 41, 45, 54, 5...   \n",
       "4               4444  [0, 12, 27, 31, 40, 56, 73, 74, 80, 97, 101, 1...   \n",
       "\n",
       "                                 features_idf.values  topicDistribution.type  \\\n",
       "0  [1.264359629051574, 2.672235245786502, 0.78028...                       1   \n",
       "1  [1.264359629051574, 1.3312618459798278, 2.1505...                       1   \n",
       "2  [1.8672845100989752, 1.9968927689697415, 8.016...                       1   \n",
       "3  [1.2448563400659836, 0.6656309229899139, 0.716...                       1   \n",
       "4  [1.8672845100989752, 2.9135879822916877, 3.598...                       1   \n",
       "\n",
       "   topicDistribution.size topicDistribution.indices  \\\n",
       "0                    <NA>                        []   \n",
       "1                    <NA>                        []   \n",
       "2                    <NA>                        []   \n",
       "3                    <NA>                        []   \n",
       "4                    <NA>                        []   \n",
       "\n",
       "                            topicDistribution.values  \n",
       "0  [0.0002747257643554155, 0.000370430728967976, ...  \n",
       "1  [0.00017208621082816756, 0.06247647418345954, ...  \n",
       "2  [0.02121493851041644, 0.0002204081812410088, 0...  \n",
       "3  [0.000144603163285717, 0.00019497790948735233,...  \n",
       "4  [7.505867153142022e-05, 0.0001012065188320117,...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81a16dab-dd14-4a0b-b410-0debd2a5578b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0002747257643554155,\n",
       " 0.000370430728967976,\n",
       " 0.000282603205748148,\n",
       " 0.14603414252700178,\n",
       " 0.00030791450869139414,\n",
       " 0.000333584922768169,\n",
       " 0.0003234378271069622,\n",
       " 0.7028763910049255,\n",
       " 0.0005492894899399529,\n",
       " 0.0002851572177409577,\n",
       " 0.0002908548275329426,\n",
       " 0.0003269576064285408,\n",
       " 0.0003105044565739272,\n",
       " 0.0003432441931907992,\n",
       " 0.03424633759100853,\n",
       " 0.00038467420619251586,\n",
       " 0.0004595401079561313,\n",
       " 0.000319972616100213,\n",
       " 0.00034326830371517094,\n",
       " 0.1113369688940552]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics1[\"topicDistribution.values\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c352ba-18fe-447c-887d-9a9ee9831dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18de77f8-89c0-4738-acf8-080ef7698529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b04f81-d87b-45e3-9617-bafe88dd443b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86604e2e-76ea-4d94-ab06-66c794f3b48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc97784-a77b-4c43-b7b8-e3a23da18114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0ef6043c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  One of the strongest techniques available for showing lower bounds on quantum communication complexity is the logarithm of the approximation rank of the communication matrix--the minimum rank of a matrix which is entrywise close to the communication matrix. This technique has two main drawbacks: it is difficult to compute, and it is not known to lower bound quantum communication complexity with entanglement.   Linial and Shraibman recently introduced a norm, called gamma_2^{alpha}, to quantum communication complexity, showing that it can be used to lower bound communication with entanglement. Here the parameter alpha is a measure of approximation which is related to the allowable error probability of the protocol. This bound can be written as a semidefinite program and gives bounds at least as large as many techniques in the literature, although it is smaller than the corresponding alpha-approximation rank, rk_alpha. We show that in fact log gamma_2^{alpha}(A)$ and log rk_{alpha}(A)$ agree up to small factors. As corollaries we obtain a constant factor polynomial time approximation algorithm to the logarithm of approximate rank, and that the logarithm of approximation rank is a lower bound for quantum communication complexity with entanglement. '"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.abstract[0].replace(\"\\n\",\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f546ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['id','title','abstract','authors','Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4c5ba2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0809.2093',\n",
       " '0904.1538',\n",
       " '0906.4316',\n",
       " '0912.0228',\n",
       " '1004.3608',\n",
       " '1007.3881',\n",
       " '1010.4059',\n",
       " '1101.2575',\n",
       " '1108.3516',\n",
       " '1111.4831']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outid = list(df_new.id[:10])\n",
    "outid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "529937c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = df_new[df_new['id'].isin(outid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a01400f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "dfout.abstract = dfout.abstract.apply(lambda x:x.replace(\"\\n\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b4b1e29f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  One of the strongest techniques available for showing lower bounds on quantum communication complexity is the logarithm of the approximation rank of the communication matrix--the minimum rank of a matrix which is entrywise close to the communication matrix. This technique has two main drawbacks: it is difficult to compute, and it is not known to lower bound quantum communication complexity with entanglement.   Linial and Shraibman recently introduced a norm, called gamma_2^{alpha}, to quantum communication complexity, showing that it can be used to lower bound communication with entanglement. Here the parameter alpha is a measure of approximation which is related to the allowable error probability of the protocol. This bound can be written as a semidefinite program and gives bounds at least as large as many techniques in the literature, although it is smaller than the corresponding alpha-approximation rank, rk_alpha. We show that in fact log gamma_2^{alpha}(A)$ and log rk_{alpha}(A)$ agree up to small factors. As corollaries we obtain a constant factor polynomial time approximation algorithm to the logarithm of approximate rank, and that the logarithm of approximation rank is a lower bound for quantum communication complexity with entanglement. '"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.abstract[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c662466d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[{\"id\":\"0809.2093\",\"title\":\"An approximation algorithm for approximation rank\",\"abstract\":\"  One of the strongest techniques available for showing lower bounds on quantum\\\\ncommunication complexity is the logarithm of the approximation rank of the\\\\ncommunication matrix--the minimum rank of a matrix which is entrywise close to\\\\nthe communication matrix. This technique has two main drawbacks: it is\\\\ndifficult to compute, and it is not known to lower bound quantum communication\\\\ncomplexity with entanglement.\\\\n  Linial and Shraibman recently introduced a norm, called gamma_2^{alpha}, to\\\\nquantum communication complexity, showing that it can be used to lower bound\\\\ncommunication with entanglement. Here the parameter alpha is a measure of\\\\napproximation which is related to the allowable error probability of the\\\\nprotocol. This bound can be written as a semidefinite program and gives bounds\\\\nat least as large as many techniques in the literature, although it is smaller\\\\nthan the corresponding alpha-approximation rank, rk_alpha. We show that in fact\\\\nlog gamma_2^{alpha}(A)$ and log rk_{alpha}(A)$ agree up to small factors. As\\\\ncorollaries we obtain a constant factor polynomial time approximation algorithm\\\\nto the logarithm of approximate rank, and that the logarithm of approximation\\\\nrank is a lower bound for quantum communication complexity with entanglement.\\\\n\",\"authors\":\"Troy Lee, Adi Shraibman\",\"Year\":2021},{\"id\":\"0904.1538\",\"title\":\"Shannon-Kotel\\'nikov Mappings for Analog Point-to-Point Communications\",\"abstract\":\"  In this paper an approach to joint source-channel coding (JSCC) named\\\\nShannon-Kotel\\'nikov mappings (S-K mappings) is presented. S-K mappings are\\\\ncontinuous, or piecewise continuous direct source-to-channel mappings operating\\\\ndirectly on amplitude continuous and discrete time signals. Such mappings\\\\ninclude several existing JSCC schemes as special cases. Many existing\\\\napproaches to analog- or hybrid discrete analog JSCC provide both excellent\\\\nperformance as well as robustness to variations in noise level. This at low\\\\ndelay and relatively low complexity. However, a theory explaining their\\\\nperformance and behaviour on a general basis, as well as guidelines on how to\\\\nconstruct close to optimal mappings in general, does not currently exist.\\\\nTherefore, such mappings are often found based on educated guesses inspired of\\\\nconfigurations that are known in advance to produce good solutions, combination\\\\nof already existing mappings, numerical optimization or machine learning\\\\nmethods.\\\\n  The objective of this paper is to introduce a theoretical framework for\\\\nanalysis of analog- or hybrid discrete analog S-K mappings. This framework will\\\\nenable calculation of distortion when applying such schemes on point-to-point\\\\nlinks, reveal more about their fundamental nature, and provide guidelines on\\\\nhow they should be constructed in order to perform well at both low and\\\\narbitrary complexity and delay. Such guidelines will likely help constrain\\\\nsolutions to numerical approaches and help explain why machine learning\\\\napproaches finds the solutions they do. This task is difficult and we do not\\\\nprovide a complete framework at this stage: We focus on high SNR and memoryless\\\\nsources with an arbitrary continuous unimodal density function and memoryless\\\\nGaussian channels. We also provide example of mappings based on surfaces which\\\\nare chosen based on the provided theory.\\\\n\",\"authors\":\"P{\\\\\\\\aa}l Anders Floor and Tor A. Ramstad\",\"Year\":2021},{\"id\":\"0906.4316\",\"title\":\"Constructive Decision Theory\",\"abstract\":\"  In most contemporary approaches to decision making, a decision problem is\\\\ndescribed by a sets of states and set of outcomes, and a rich set of acts,\\\\nwhich are functions from states to outcomes over which the decision maker (DM)\\\\nhas preferences. Most interesting decision problems, however, do not come with\\\\na state space and an outcome space. Indeed, in complex problems it is often far\\\\nfrom clear what the state and outcome spaces would be. We present an\\\\nalternative foundation for decision making, in which the primitive objects of\\\\nchoice are syntactic programs. A representation theorem is proved in the spirit\\\\nof standard representation theorems, showing that if the DM\\'s preference\\\\nrelation on objects of choice satisfies appropriate axioms, then there exist a\\\\nset S of states, a set O of outcomes, a way of interpreting the objects of\\\\nchoice as functions from S to O, a probability on S, and a utility function on\\\\nO, such that the DM prefers choice a to choice b if and only if the expected\\\\nutility of a is higher than that of b. Thus, the state space and outcome space\\\\nare subjective, just like the probability and utility; they are not part of the\\\\ndescription of the problem. In principle, a modeler can test for SEU behavior\\\\nwithout having access to states or outcomes. We illustrate the power of our\\\\napproach by showing that it can capture decision makers who are subject to\\\\nframing effects.\\\\n\",\"authors\":\"Lawrence Blume, David Easley, and Joseph Y. Halpern\",\"Year\":2021},{\"id\":\"0912.0228\",\"title\":\"Answering Hilbert\\'s 1st Problem\",\"abstract\":\"  Hilbert\\'s first problem is of importance in relation to work being done in\\\\ncomputational systems. It is the question of equipollence of natural and real\\\\nnumbers. By construction equipollence is established for real numbers in open\\\\ninterval (0, 1) and natural numbers and, from such to all real numbers.\\\\nConstruction stands in contradiction of the generally accepted diagonal\\\\nargument of Cantor. Mathematics being irrefutable, in absence rejection of all\\\\ntheory of mathematics and logic, the problem exists in acceptance; that itself\\\\narises of more fundamental a problem in science generally. The problem within\\\\nHilbert\\'s problem is of Schopenhauer\\'s, et al, \\\\\"will and representation\\\\\" born.\\\\n\",\"authors\":\"Charles Sauerbier\",\"Year\":2021},{\"id\":\"1004.3608\",\"title\":\"The complexity of multiple-precision arithmetic\",\"abstract\":\"  In studying the complexity of iterative processes it is usually assumed that\\\\nthe arithmetic operations of addition, multiplication, and division can be\\\\nperformed in certain constant times. This assumption is invalid if the\\\\nprecision required increases as the computation proceeds. We give upper and\\\\nlower bounds on the number of single-precision operations required to perform\\\\nvarious multiple-precision operations, and deduce some interesting consequences\\\\nconcerning the relative efficiencies of methods for solving nonlinear equations\\\\nusing variable-length multiple-precision arithmetic. A postscript describes\\\\nmore recent developments.\\\\n\",\"authors\":\"Richard P. Brent\",\"Year\":2021},{\"id\":\"1007.3881\",\"title\":\"Orthogonal multifilters image processing of astronomical images from\\\\n  scanned photographic plates\",\"abstract\":\"  In this paper orthogonal multifilters for astronomical image processing are\\\\npresented. We obtained new orthogonal multifilters based on the orthogonal\\\\nwavelet of Haar and Daubechies. Recently, multiwavelets have been introduced as\\\\na more powerful multiscale analysis tool. It adds several degrees of freedom in\\\\nmultifilter design and makes it possible to have several useful properties such\\\\nas symmetry, orthogonality, short support, and a higher number of vanishing\\\\nmoments simultaneously. Multifilter decomposition of scanned photographic\\\\nplates with astronomical images is made.\\\\n\",\"authors\":\"Vasil Kolev\",\"Year\":2021},{\"id\":\"1010.4059\",\"title\":\"Multiplierless Modules for Forward and Backward Integer Wavelet\\\\n  Transform\",\"abstract\":\"  This article is about the architecture of a lossless wavelet filter bank with\\\\nreprogrammable logic. It is based on second generation of wavelets with a\\\\nreduced of number of operations. A new basic structure for parallel\\\\narchitecture and modules to forward and backward integer discrete wavelet\\\\ntransform is proposed.\\\\n\",\"authors\":\"Vasil Kolev\",\"Year\":2021},{\"id\":\"1101.2575\",\"title\":\"Errata list for \\\\\"Error Control Coding\\\\\" by Lin and Costello\",\"abstract\":\"  This document lists some errors found in the second edition of Error Control\\\\nCoding by Shu Lin and Daniel J. Costello, Jr.\\\\n\",\"authors\":\"Erik Agrell\",\"Year\":2021},{\"id\":\"1108.3516\",\"title\":\"Model for networks of spatial objects and simulation of geographical\\\\n  phenomena propagation\",\"abstract\":\"  The topic of this paper is the presentation of a new network model designed\\\\nfor networks consisting of spatial objects. This model allows the development\\\\nof more advance representations of systems of networked objects and the study\\\\nof geographical phenomena propagated through networks. The capabilities of the\\\\nmodel in simulation of geographical phenomena propagation are also studied and\\\\nrelevant algorithms are presented. As examples of use, modeling of water supply\\\\nnetwork and the simulation of traffic flow in road networks are presented.\\\\n\",\"authors\":\"Panteleimon Rodis\",\"Year\":2021},{\"id\":\"1111.4831\",\"title\":\"Analytical calculation of optimal POVM for unambiguous discrimination of\\\\n  quantum states using KKT method\",\"abstract\":\"  In the present paper, an exact analytic solution for the optimal unambiguous\\\\nstate discrimination (OPUSD) problem involving an arbitrary number of pure\\\\nlinearly independent quantum states with real and complex inner product is\\\\npresented. Using semidefinite programming and Karush-Kuhn-Tucker convex\\\\noptimization method, we derive an analytical formula which shows the relation\\\\nbetween optimal solution of unambiguous state discrimination problem and an\\\\narbitrary number of pure linearly independent quantum states.\\\\n\",\"authors\":\"N. Karimi\",\"Year\":2021}]'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfout.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2eccfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outnew = list(df_new.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8055254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in outid:\n",
    "#     print(x)\n",
    "    try:\n",
    "        print(outnew.index(x))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "34cd696d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0710.0761',\n",
       " '0712.4271',\n",
       " '0804.1315',\n",
       " '0802.3070',\n",
       " '0711.2693',\n",
       " '0705.4077',\n",
       " '0711.0439',\n",
       " '0708.4367',\n",
       " '0802.4166',\n",
       " '0707.1613',\n",
       " '0803.4510',\n",
       " '0803.0630',\n",
       " '0705.0124',\n",
       " '0706.3184',\n",
       " '0707.1198']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6ba7ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yjagilanka/Desktop/sem2/DIC/Document_Retrieval_NLP/data/OutputFiles_ComputerScience\n"
     ]
    }
   ],
   "source": [
    "cd OutputFiles_ComputerScience/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b4e3ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mtopics_LDA.parquet\u001b[m\u001b[m/                \u001b[34mtrans_sub_df_tfidf.parquet\u001b[m\u001b[m/\n",
      "\u001b[34mtrans_sub_df.parquet\u001b[m\u001b[m/              \u001b[34mtransformed_LDA_TopicDist.parquet\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3cac67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('topics_LDA.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aa5fd292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "      <th>words_in_topic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[60, 106, 140, 296, 267, 338, 280, 91, 388, 43...</td>\n",
       "      <td>[0.011366028474922544, 0.010174892183843215, 0...</td>\n",
       "      <td>[object, video, 3d, scene, pose, motion, tempo...</td>\n",
       "      <td>0704.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[46, 231, 362, 66, 25, 679, 652, 774, 593, 477...</td>\n",
       "      <td>[0.007370446252777693, 0.006947803359488921, 0...</td>\n",
       "      <td>[user, social, ai, research, study, media, cov...</td>\n",
       "      <td>0704.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[396, 215, 228, 630, 1043, 503, 918, 1083, 154...</td>\n",
       "      <td>[0.019190518824472567, 0.01483736298056689, 0....</td>\n",
       "      <td>[speech, question, query, retrieval, speaker, ...</td>\n",
       "      <td>0704.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[370, 538, 309, 284, 156, 46, 146, 279, 845, 4...</td>\n",
       "      <td>[0.010934919067909646, 0.008042660971095251, 0...</td>\n",
       "      <td>[channel, item, matrix, signal, scheme, user, ...</td>\n",
       "      <td>0704.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[213, 285, 316, 214, 350, 648, 672, 241, 903, ...</td>\n",
       "      <td>[0.009879014206956718, 0.008328467093040902, 0...</td>\n",
       "      <td>[device, privacy, security, communication, ser...</td>\n",
       "      <td>0704.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                                        termIndices  \\\n",
       "0      0  [60, 106, 140, 296, 267, 338, 280, 91, 388, 43...   \n",
       "1      1  [46, 231, 362, 66, 25, 679, 652, 774, 593, 477...   \n",
       "2      2  [396, 215, 228, 630, 1043, 503, 918, 1083, 154...   \n",
       "3      3  [370, 538, 309, 284, 156, 46, 146, 279, 845, 4...   \n",
       "4      4  [213, 285, 316, 214, 350, 648, 672, 241, 903, ...   \n",
       "\n",
       "                                         termWeights  \\\n",
       "0  [0.011366028474922544, 0.010174892183843215, 0...   \n",
       "1  [0.007370446252777693, 0.006947803359488921, 0...   \n",
       "2  [0.019190518824472567, 0.01483736298056689, 0....   \n",
       "3  [0.010934919067909646, 0.008042660971095251, 0...   \n",
       "4  [0.009879014206956718, 0.008328467093040902, 0...   \n",
       "\n",
       "                                      words_in_topic         id  \n",
       "0  [object, video, 3d, scene, pose, motion, tempo...  0704.0001  \n",
       "1  [user, social, ai, research, study, media, cov...  0704.0002  \n",
       "2  [speech, question, query, retrieval, speaker, ...  0704.0003  \n",
       "3  [channel, item, matrix, signal, scheme, user, ...  0704.0004  \n",
       "4  [device, privacy, security, communication, ser...  0704.0005  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "06583ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finshed_lemma</th>\n",
       "      <th>id</th>\n",
       "      <th>features_cv.type</th>\n",
       "      <th>features_cv.size</th>\n",
       "      <th>features_cv.indices</th>\n",
       "      <th>features_cv.values</th>\n",
       "      <th>features_idf.type</th>\n",
       "      <th>features_idf.size</th>\n",
       "      <th>features_idf.indices</th>\n",
       "      <th>features_idf.values</th>\n",
       "      <th>topicDistribution.type</th>\n",
       "      <th>topicDistribution.size</th>\n",
       "      <th>topicDistribution.indices</th>\n",
       "      <th>topicDistribution.values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[one, strong, technique, available, show, low,...</td>\n",
       "      <td>0704.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[1, 7, 27, 29, 30, 44, 51, 53, 55, 64, 82, 93,...</td>\n",
       "      <td>[1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[1, 7, 27, 29, 30, 44, 51, 53, 55, 64, 82, 93,...</td>\n",
       "      <td>[0.6002401909558803, 2.4175319950647953, 1.650...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0001542858662773005, 0.00014366900049422125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[paper, approach, joint, sourcechannel, coding...</td>\n",
       "      <td>0704.0002</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[2, 4, 11, 12, 13, 17, 19, 21, 23, 27, 31, 34,...</td>\n",
       "      <td>[2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 5.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[2, 4, 11, 12, 13, 17, 19, 21, 23, 27, 31, 34,...</td>\n",
       "      <td>[1.7715262112032415, 0.9004708053657116, 1.315...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[9.979491569639565e-05, 0.09275852544594433, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[contemporary, approaches, decision, make, dec...</td>\n",
       "      <td>0704.0003</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[7, 9, 19, 26, 31, 34, 41, 45, 52, 54, 60, 62,...</td>\n",
       "      <td>[2.0, 4.0, 1.0, 5.0, 1.0, 1.0, 1.0, 2.0, 2.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[7, 9, 19, 26, 31, 34, 41, 45, 52, 54, 60, 62,...</td>\n",
       "      <td>[1.6116879967098636, 4.889919483580155, 1.4276...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.042510088741187765, 0.024628013530354608, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hilberts, first, problem, importance, relatio...</td>\n",
       "      <td>0704.0004</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[9, 10, 16, 41, 45, 50, 59, 197, 204, 210, 215...</td>\n",
       "      <td>[5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 2.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[9, 10, 16, 41, 45, 50, 59, 197, 204, 210, 215...</td>\n",
       "      <td>[6.112399354475194, 1.3924640539291526, 1.2416...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0003021266866393672, 0.1110698607376876, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[study, complexity, iterative, process, usuall...</td>\n",
       "      <td>0704.0005</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[1, 4, 25, 27, 36, 59, 64, 69, 84, 95, 98, 110...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[1, 4, 25, 27, 36, 59, 64, 69, 84, 95, 98, 110...</td>\n",
       "      <td>[0.6002401909558803, 0.9004708053657116, 1.443...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.00031550412348383875, 0.0002937933564467859...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69417</th>\n",
       "      <td>[optical, device, lie, heart, technology, see,...</td>\n",
       "      <td>0806.3404</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[1, 2, 4, 6, 10, 17, 19, 25, 28, 37, 40, 44, 4...</td>\n",
       "      <td>[3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[1, 2, 4, 6, 10, 17, 19, 25, 28, 37, 40, 44, 4...</td>\n",
       "      <td>[1.800720572867641, 1.7715262112032415, 0.9004...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.00011814126834775631, 0.0001100116108615550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69418</th>\n",
       "      <td>[online, product, review, valuable, resource, ...</td>\n",
       "      <td>0806.3405</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[1, 2, 12, 13, 16, 23, 30, 31, 32, 36, 37, 38,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[1, 2, 12, 13, 16, 23, 30, 31, 32, 36, 37, 38,...</td>\n",
       "      <td>[0.6002401909558803, 0.8857631056016207, 1.124...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.00011638292215732516, 0.7842895366635606, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69419</th>\n",
       "      <td>[study, problem, schedule, equallength, job, r...</td>\n",
       "      <td>0806.3406</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[7, 8, 9, 25, 27, 29, 59, 64, 150, 235, 261, 2...</td>\n",
       "      <td>[1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[7, 8, 9, 25, 27, 29, 59, 64, 150, 235, 261, 2...</td>\n",
       "      <td>[0.8058439983549318, 0.8736122878191082, 3.667...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.000520359387769584, 0.0004845519233511543, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69420</th>\n",
       "      <td>[survey, averagecase, complexity, problem, np,...</td>\n",
       "      <td>0806.3407</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[7, 8, 9, 17, 24, 31, 47, 55, 92, 98, 109, 125...</td>\n",
       "      <td>[1.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[7, 8, 9, 17, 24, 31, 47, 55, 92, 98, 109, 125...</td>\n",
       "      <td>[0.8058439983549318, 4.368061439095541, 8.5573...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.00016951780945935002, 0.0001578527899904093...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69421</th>\n",
       "      <td>[dense, subgraphs, sparse, graph, communities,...</td>\n",
       "      <td>0806.3408</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[3, 4, 6, 7, 8, 12, 17, 24, 26, 32, 33, 38, 41...</td>\n",
       "      <td>[2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>15976</td>\n",
       "      <td>[3, 4, 6, 7, 8, 12, 17, 24, 26, 32, 33, 38, 41...</td>\n",
       "      <td>[1.3106782012329334, 1.8009416107314231, 1.121...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0002579263739059967, 0.12890499650674278, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69422 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           finshed_lemma         id  \\\n",
       "0      [one, strong, technique, available, show, low,...  0704.0001   \n",
       "1      [paper, approach, joint, sourcechannel, coding...  0704.0002   \n",
       "2      [contemporary, approaches, decision, make, dec...  0704.0003   \n",
       "3      [hilberts, first, problem, importance, relatio...  0704.0004   \n",
       "4      [study, complexity, iterative, process, usuall...  0704.0005   \n",
       "...                                                  ...        ...   \n",
       "69417  [optical, device, lie, heart, technology, see,...  0806.3404   \n",
       "69418  [online, product, review, valuable, resource, ...  0806.3405   \n",
       "69419  [study, problem, schedule, equallength, job, r...  0806.3406   \n",
       "69420  [survey, averagecase, complexity, problem, np,...  0806.3407   \n",
       "69421  [dense, subgraphs, sparse, graph, communities,...  0806.3408   \n",
       "\n",
       "       features_cv.type  features_cv.size  \\\n",
       "0                     0             15976   \n",
       "1                     0             15976   \n",
       "2                     0             15976   \n",
       "3                     0             15976   \n",
       "4                     0             15976   \n",
       "...                 ...               ...   \n",
       "69417                 0             15976   \n",
       "69418                 0             15976   \n",
       "69419                 0             15976   \n",
       "69420                 0             15976   \n",
       "69421                 0             15976   \n",
       "\n",
       "                                     features_cv.indices  \\\n",
       "0      [1, 7, 27, 29, 30, 44, 51, 53, 55, 64, 82, 93,...   \n",
       "1      [2, 4, 11, 12, 13, 17, 19, 21, 23, 27, 31, 34,...   \n",
       "2      [7, 9, 19, 26, 31, 34, 41, 45, 52, 54, 60, 62,...   \n",
       "3      [9, 10, 16, 41, 45, 50, 59, 197, 204, 210, 215...   \n",
       "4      [1, 4, 25, 27, 36, 59, 64, 69, 84, 95, 98, 110...   \n",
       "...                                                  ...   \n",
       "69417  [1, 2, 4, 6, 10, 17, 19, 25, 28, 37, 40, 44, 4...   \n",
       "69418  [1, 2, 12, 13, 16, 23, 30, 31, 32, 36, 37, 38,...   \n",
       "69419  [7, 8, 9, 25, 27, 29, 59, 64, 150, 235, 261, 2...   \n",
       "69420  [7, 8, 9, 17, 24, 31, 47, 55, 92, 98, 109, 125...   \n",
       "69421  [3, 4, 6, 7, 8, 12, 17, 24, 26, 32, 33, 38, 41...   \n",
       "\n",
       "                                      features_cv.values  features_idf.type  \\\n",
       "0      [1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, ...                  0   \n",
       "1      [2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 5.0, ...                  0   \n",
       "2      [2.0, 4.0, 1.0, 5.0, 1.0, 1.0, 1.0, 2.0, 2.0, ...                  0   \n",
       "3      [5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 2.0, ...                  0   \n",
       "4      [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, ...                  0   \n",
       "...                                                  ...                ...   \n",
       "69417  [3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, ...                  0   \n",
       "69418  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                  0   \n",
       "69419  [1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, ...                  0   \n",
       "69420  [1.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, ...                  0   \n",
       "69421  [2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...                  0   \n",
       "\n",
       "       features_idf.size                               features_idf.indices  \\\n",
       "0                  15976  [1, 7, 27, 29, 30, 44, 51, 53, 55, 64, 82, 93,...   \n",
       "1                  15976  [2, 4, 11, 12, 13, 17, 19, 21, 23, 27, 31, 34,...   \n",
       "2                  15976  [7, 9, 19, 26, 31, 34, 41, 45, 52, 54, 60, 62,...   \n",
       "3                  15976  [9, 10, 16, 41, 45, 50, 59, 197, 204, 210, 215...   \n",
       "4                  15976  [1, 4, 25, 27, 36, 59, 64, 69, 84, 95, 98, 110...   \n",
       "...                  ...                                                ...   \n",
       "69417              15976  [1, 2, 4, 6, 10, 17, 19, 25, 28, 37, 40, 44, 4...   \n",
       "69418              15976  [1, 2, 12, 13, 16, 23, 30, 31, 32, 36, 37, 38,...   \n",
       "69419              15976  [7, 8, 9, 25, 27, 29, 59, 64, 150, 235, 261, 2...   \n",
       "69420              15976  [7, 8, 9, 17, 24, 31, 47, 55, 92, 98, 109, 125...   \n",
       "69421              15976  [3, 4, 6, 7, 8, 12, 17, 24, 26, 32, 33, 38, 41...   \n",
       "\n",
       "                                     features_idf.values  \\\n",
       "0      [0.6002401909558803, 2.4175319950647953, 1.650...   \n",
       "1      [1.7715262112032415, 0.9004708053657116, 1.315...   \n",
       "2      [1.6116879967098636, 4.889919483580155, 1.4276...   \n",
       "3      [6.112399354475194, 1.3924640539291526, 1.2416...   \n",
       "4      [0.6002401909558803, 0.9004708053657116, 1.443...   \n",
       "...                                                  ...   \n",
       "69417  [1.800720572867641, 1.7715262112032415, 0.9004...   \n",
       "69418  [0.6002401909558803, 0.8857631056016207, 1.124...   \n",
       "69419  [0.8058439983549318, 0.8736122878191082, 3.667...   \n",
       "69420  [0.8058439983549318, 4.368061439095541, 8.5573...   \n",
       "69421  [1.3106782012329334, 1.8009416107314231, 1.121...   \n",
       "\n",
       "       topicDistribution.type  topicDistribution.size  \\\n",
       "0                           1                    <NA>   \n",
       "1                           1                    <NA>   \n",
       "2                           1                    <NA>   \n",
       "3                           1                    <NA>   \n",
       "4                           1                    <NA>   \n",
       "...                       ...                     ...   \n",
       "69417                       1                    <NA>   \n",
       "69418                       1                    <NA>   \n",
       "69419                       1                    <NA>   \n",
       "69420                       1                    <NA>   \n",
       "69421                       1                    <NA>   \n",
       "\n",
       "      topicDistribution.indices  \\\n",
       "0                            []   \n",
       "1                            []   \n",
       "2                            []   \n",
       "3                            []   \n",
       "4                            []   \n",
       "...                         ...   \n",
       "69417                        []   \n",
       "69418                        []   \n",
       "69419                        []   \n",
       "69420                        []   \n",
       "69421                        []   \n",
       "\n",
       "                                topicDistribution.values  \n",
       "0      [0.0001542858662773005, 0.00014366900049422125...  \n",
       "1      [9.979491569639565e-05, 0.09275852544594433, 7...  \n",
       "2      [0.042510088741187765, 0.024628013530354608, 0...  \n",
       "3      [0.0003021266866393672, 0.1110698607376876, 0....  \n",
       "4      [0.00031550412348383875, 0.0002937933564467859...  \n",
       "...                                                  ...  \n",
       "69417  [0.00011814126834775631, 0.0001100116108615550...  \n",
       "69418  [0.00011638292215732516, 0.7842895366635606, 0...  \n",
       "69419  [0.000520359387769584, 0.0004845519233511543, ...  \n",
       "69420  [0.00016951780945935002, 0.0001578527899904093...  \n",
       "69421  [0.0002579263739059967, 0.12890499650674278, 0...  \n",
       "\n",
       "[69422 rows x 14 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_parquet('transformed_LDA_TopicDist.parquet', engine='fastparquet')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2280594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"convolution neural networks for image scene detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0904dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "310d52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_query_process(test):\n",
    "    words = test.split(\" \")\n",
    "    words = [word.lower() for word in words]\n",
    "    data = [word for word in words if not word in set(stopwords.words('english'))]\n",
    "    lemmmatizer=WordNetLemmatizer()\n",
    "    words = [lemmmatizer.lemmatize(word.lower()) for word in data if word not in set(stopwords.words('english'))]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39984b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = initial_query_process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2dce129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>termIndices</th>\n",
       "      <th>termWeights</th>\n",
       "      <th>words_in_topic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[60, 106, 140, 296, 267, 338, 280, 91, 388, 43...</td>\n",
       "      <td>[0.011366028474922544, 0.010174892183843215, 0...</td>\n",
       "      <td>[object, video, 3d, scene, pose, motion, tempo...</td>\n",
       "      <td>0704.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[46, 231, 362, 66, 25, 679, 652, 774, 593, 477...</td>\n",
       "      <td>[0.007370446252777693, 0.006947803359488921, 0...</td>\n",
       "      <td>[user, social, ai, research, study, media, cov...</td>\n",
       "      <td>0704.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[396, 215, 228, 630, 1043, 503, 918, 1083, 154...</td>\n",
       "      <td>[0.019190518824472567, 0.01483736298056689, 0....</td>\n",
       "      <td>[speech, question, query, retrieval, speaker, ...</td>\n",
       "      <td>0704.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[370, 538, 309, 284, 156, 46, 146, 279, 845, 4...</td>\n",
       "      <td>[0.010934919067909646, 0.008042660971095251, 0...</td>\n",
       "      <td>[channel, item, matrix, signal, scheme, user, ...</td>\n",
       "      <td>0704.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[213, 285, 316, 214, 350, 648, 672, 241, 903, ...</td>\n",
       "      <td>[0.009879014206956718, 0.008328467093040902, 0...</td>\n",
       "      <td>[device, privacy, security, communication, ser...</td>\n",
       "      <td>0704.0005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic                                        termIndices  \\\n",
       "0      0  [60, 106, 140, 296, 267, 338, 280, 91, 388, 43...   \n",
       "1      1  [46, 231, 362, 66, 25, 679, 652, 774, 593, 477...   \n",
       "2      2  [396, 215, 228, 630, 1043, 503, 918, 1083, 154...   \n",
       "3      3  [370, 538, 309, 284, 156, 46, 146, 279, 845, 4...   \n",
       "4      4  [213, 285, 316, 214, 350, 648, 672, 241, 903, ...   \n",
       "\n",
       "                                         termWeights  \\\n",
       "0  [0.011366028474922544, 0.010174892183843215, 0...   \n",
       "1  [0.007370446252777693, 0.006947803359488921, 0...   \n",
       "2  [0.019190518824472567, 0.01483736298056689, 0....   \n",
       "3  [0.010934919067909646, 0.008042660971095251, 0...   \n",
       "4  [0.009879014206956718, 0.008328467093040902, 0...   \n",
       "\n",
       "                                      words_in_topic         id  \n",
       "0  [object, video, 3d, scene, pose, motion, tempo...  0704.0001  \n",
       "1  [user, social, ai, research, study, media, cov...  0704.0002  \n",
       "2  [speech, question, query, retrieval, speaker, ...  0704.0003  \n",
       "3  [channel, item, matrix, signal, scheme, user, ...  0704.0004  \n",
       "4  [device, privacy, security, communication, ser...  0704.0005  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f9a8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for x in df['words_in_topic']:\n",
    "    l.extend(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c16bc37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfcf4059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.016377309792069725,\n",
       " 0,\n",
       " 0,\n",
       " 0.0024421580468462294,\n",
       " 0.005034243223381492,\n",
       " 0,\n",
       " 0,\n",
       " 0.028614886441241126,\n",
       " 0.016150880987708536,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.00278462791034974,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.03112057185829214,\n",
       " 0.002179416246659914,\n",
       " 0]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topicid_getter(df,words):\n",
    "    topic = []\n",
    "    for index, row in df.iterrows():\n",
    "        weight = 0\n",
    "        for t in words:\n",
    "            try:\n",
    "                arg = row['words_in_topic'].index(t)\n",
    "                weight+= row['termWeights'][arg]\n",
    "            except ValueError:\n",
    "                pass\n",
    "        topic.append(weight)\n",
    "    topicid = topic.index(max(topic)) + 1\n",
    "    return topicid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e9bed803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8f252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
